# ./tests/test_featurewiz_model.py  (New File or renamed existing test file)

import pytest # Import pytest
import polars as pl
import numpy as np
import pandas as pd # Still needed if sklearn returns pandas objects
from sklearn.model_selection import train_test_split # Using sklearn split as in original script
from sklearn.datasets import make_classification
# Removed RandomForest imports as they weren't used with selected features in the original script's logic flow
# from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from featurewiz_polars import print_classification_metrics, print_regression_metrics
from featurewiz_polars import FeatureWiz, FeatureWiz_Model # Assuming FeatureWiz_Model exists
# from featurewiz_polars import Sulov_MRMR # This wasn't used directly in the __main__ block
import time
# Removed pdb import

# Define the test function
def test_featurewiz_model_classification_workflow():
    """
    Tests the classification workflow using FeatureWiz_Model based on the provided script.
    Uses synthetic data generated by make_classification.
    """
    # --- 1. Data Generation (Using make_classification as in script's commented section) ---
    n_samples = 1000 # Reduced sample size for faster test execution
    n_features = 20
    n_informative = 10
    n_redundant = 4
    random_state = 42

    X_np, y_np = make_classification(n_samples=n_samples, n_features=n_features,
                                     n_informative=n_informative, n_redundant=n_redundant,
                                     random_state=random_state)

    # Create feature names
    feature_names = [f"feature_{i}" for i in range(n_features)]

    # Convert to Polars DataFrame
    X_pl = pl.DataFrame(X_np, schema=feature_names)
    y_pl = pl.Series("target", y_np) # Name the target series

    # Combine for splitting (if needed, though sklearn handles separate X, y)
    # df = pl.concat([X_pl, y_pl.to_frame()], how="horizontal") # Keep X and y separate for sklearn split

    print(f'Generated data shape: {X_pl.shape}')
    target = 'target' # Target name defined
    model_type = 'Classification' # Model type defined
    predictors = feature_names # Predictors are all feature names

    # Assert data dimensions
    assert X_pl.shape == (n_samples, n_features)
    assert y_pl.len() == n_samples
    print('Data dimensions (rows x cols) = %d dims' % (int(X_pl.shape[0] * X_pl.shape[1])))

    # --- 2. Data Splitting (Using sklearn.model_selection.train_test_split as in script) ---
    # Note: sklearn split returns Pandas objects if input is Pandas, or Numpy if input is Numpy.
    # It might handle Polars now, but let's convert to numpy to be safe and match likely original intent if Polars support was nascent.
    # If your library's train_test_split is preferred, you'd swap this.
    try:
        # Attempt direct split (requires recent sklearn that handles Polars)
        X_train_pl, X_test_pl, y_train_pl, y_test_pl = train_test_split(
            X_pl, y_pl, test_size=0.2, random_state=random_state
        )
        # Ensure outputs are Polars Series/DataFrame if successful
        assert isinstance(X_train_pl, pl.DataFrame)
        assert isinstance(y_train_pl, pl.Series)

    except TypeError:
        # Fallback: Convert to NumPy for sklearn if direct Polars split fails
        print("Direct Polars split failed, converting to NumPy for train_test_split.")
        X_train_np, X_test_np, y_train_np, y_test_np = train_test_split(
            X_np, y_np, test_size=0.2, random_state=random_state
        )
        # Convert back to Polars
        X_train_pl = pl.DataFrame(X_train_np, schema=feature_names)
        X_test_pl = pl.DataFrame(X_test_np, schema=feature_names)
        y_train_pl = pl.Series("target", y_train_np)
        y_test_pl = pl.Series("target", y_test_np)

    # Assert shapes after split
    assert X_train_pl.shape[0] == y_train_pl.len()
    assert X_test_pl.shape[0] == y_test_pl.len()
    assert X_train_pl.shape[1] == n_features
    assert X_test_pl.shape[1] == n_features


    # --- 3. FeatureWiz_Model Initialization and Execution ---
    start_time = time.time()

    # Initialize FeatureWiz_Model (using parameters from script)
    mrmr = FeatureWiz_Model(model_type=model_type,
                            corr_limit=0.7, # Assuming this parameter exists
                            category_encoders='onehot',
                            classic=True, # Assuming this parameter exists
                            verbose=0)

    # Fit using the training data (Using fit_predict as in the script - unconventional)
    # NOTE: fit_predict usually returns predictions, but the script ignores them.
    # Assuming it modifies `mrmr` object internally (e.g., sets selected_features).
    # If it returns something useful, capture it.
    try:
         _ = mrmr.fit_predict(X_train_pl, y_train_pl) # Run as in script
         # If FeatureWiz_Model has fit() instead, that would be more standard:
         # mrmr.fit(X_train_pl, y_train_pl)
    except Exception as e:
         pytest.fail(f"mrmr.fit_predict raised an exception: {e}")


    # Get selected features
    pols_feats = mrmr.selected_features

    # Assertions on selected features
    assert isinstance(pols_feats, list)
    assert len(pols_feats) > 0, "Expected at least one feature to be selected"
    assert len(pols_feats) <= n_features, "Selected features should not exceed original number"
    print(f'{len(pols_feats)} features selected by featurewiz-polars: {pols_feats}')


    # Predict on the test data
    try:
        y_pols = mrmr.predict(X_test_pl)
    except Exception as e:
        pytest.fail(f"mrmr.predict raised an exception: {e}")

    # Assertions on predictions
    assert isinstance(y_pols, (pl.Series, np.ndarray)), "Prediction should be Polars Series or NumPy array" # Adjust type based on actual return
    assert len(y_pols) == X_test_pl.shape[0], "Number of predictions must match number of test samples"

    # --- 4. Metric Calculation (as in script) ---
    # Prepare y_test for metric function (handle potential encoding)
    try:
        # Check if target encoder exists and transform y_test
        if hasattr(mrmr, 'y_encoder') and mrmr.y_encoder is not None:
             y_test_transformed_np = mrmr.y_encoder.transform(y_test_pl).to_numpy().ravel()
        else:
             # Assume no transformation needed if no encoder
             y_test_transformed_np = y_test_pl.to_numpy().ravel()

        # Convert predictions to numpy if they aren't already
        y_pols_np = y_pols.to_numpy().ravel() if isinstance(y_pols, pl.Series) else y_pols.ravel()

        # Call the metric printing function (assertion is basically that this doesn't crash)
        print_classification_metrics(y_test_transformed_np, y_pols_np, verbose=1)

    except Exception as e:
        pytest.fail(f"print_classification_metrics raised an exception: {e}")

    # --- 5. Timing ---
    end_time = time.time()
    print('Time taken for test = %0.1f seconds' % (end_time - start_time))

